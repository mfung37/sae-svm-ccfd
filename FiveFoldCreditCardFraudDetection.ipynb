{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuHAraR7AtJd"
   },
   "source": [
    "# Hyperparameters specified in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "y264LlBIAwdg"
   },
   "outputs": [],
   "source": [
    "# no random seed given\n",
    "TESTING_SPLIT = 0.2\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Hyperparameters\n",
    "BATCHSIZE = 1024\n",
    "EPOCH = 300\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUIIgDRYK-Yc"
   },
   "source": [
    "# Importing libraries\n",
    "\n",
    "Using tensorflow implement the multilayer for the sparse auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2bKbVFuwBPoV"
   },
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/sparse-autoencoders-in-deep-learning/\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eo5PdirvL6mw"
   },
   "source": [
    "# Importing data and data preprocessing\n",
    "\n",
    "Importing data from mounted drive of the credit card data from [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud).\n",
    "\n",
    "Display the same data as shown in the paper as sample of data.\n",
    "\n",
    "Data preprocessing\n",
    "- Convert time from seconds to hour of the day\n",
    "- Apply log transformation to amount as right skewed\n",
    "- Split data into training and testing\n",
    "- Standardscaler fitted to training set then apply to training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcqNUglojT3y"
   },
   "source": [
    "# Sparse Autoencoding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "xgPJoBD2ffus"
   },
   "outputs": [],
   "source": [
    "def SAE_Model():\n",
    "  inputs = Input(shape=(30,))\n",
    "\n",
    "  encoder_1 = layers.Dense(100, activation='relu', name='encoder_1')(inputs)\n",
    "  encoded = layers.Dense(20, activation='relu', name='encode',\n",
    "                        kernel_regularizer=tf.keras.regularizers.L1(0.005))(encoder_1)\n",
    "\n",
    "  decoder_1 = layers.Dense(100, activation='relu', name='decoder_1')(encoded)\n",
    "  outputs = layers.Dense(30, activation='linear', name='output')(decoder_1)\n",
    "\n",
    "  autoencoder = Model(inputs=inputs, outputs=outputs, name='sparse_autoencoder')\n",
    "\n",
    "  adam_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "  autoencoder.compile(\n",
    "      optimizer=adam_optimizer,\n",
    "      loss='mse'\n",
    "  )\n",
    "\n",
    "  return autoencoder, encoded, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u800q20AoW_Q"
   },
   "source": [
    "# Comparison analysis between SAE-SVM vs SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "UYzK_BU-o9an"
   },
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred):\n",
    "    f2 = fbeta_score(y_true, y_pred, beta=2)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return f2, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "V102WLMdPey9"
   },
   "outputs": [],
   "source": [
    "sae_output_preds = []\n",
    "svm_output_preds = []\n",
    "y_output_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "UKjJzgZnPg__"
   },
   "outputs": [],
   "source": [
    "sae_metrics = []\n",
    "svm_metrics = []\n",
    "\n",
    "f2_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "f2_scores_sae = []\n",
    "precision_scores_sae = []\n",
    "recall_scores_sae = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78Cp8ftCghMo"
   },
   "source": [
    "# Five Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "BvYXTqlEaONK"
   },
   "outputs": [],
   "source": [
    "def five_fold_validation(dataset):\n",
    "  skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "  undersample = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "  oversample = RandomOverSampler(sampling_strategy=1.0, random_state=42)\n",
    "\n",
    "  for i, (train_idx, test_idx) in enumerate(skf.split(dataset, dataset['Class'])):\n",
    "    print(f\"Fold {i+1}\")\n",
    "    print(len(train_idx), len(test_idx))\n",
    "\n",
    "    # Use 4 subsets for training and 1 for testing\n",
    "    train_subset = dataset.iloc[train_idx]\n",
    "    test_subset = dataset.iloc[test_idx]\n",
    "\n",
    "    print(train_subset[train_subset['Class'] == 0].shape, train_subset[train_subset['Class'] == 1].shape)\n",
    "    print(test_subset[test_subset['Class'] == 0].shape, test_subset[test_subset['Class'] == 1].shape)\n",
    "\n",
    "    # Split the training\n",
    "    X_train_split = train_subset.drop('Class', axis=1)\n",
    "    y_train_split = train_subset['Class']\n",
    "    X_test_split = test_subset.drop('Class', axis=1)\n",
    "    y_test_split = test_subset['Class']\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_split)\n",
    "    X_test_scaled = scaler.transform(X_test_split)\n",
    "\n",
    "    # Undersample the data\n",
    "    # print(\"Resampling\")\n",
    "    # X_train_undersample, y_train_undersample = undersample.fit_resample(X_train_scaled, y_train_split)\n",
    "    # print(len(X_train_undersample))\n",
    "    # X_train_oversample, y_train_oversample = oversample.fit_resample(X_train_undersample, y_train_undersample)\n",
    "\n",
    "    X_train_final = X_train_scaled\n",
    "    y_train_final = y_train_split\n",
    "    # print(np.sum(y_train_final == 0), np.sum(y_train_final == 1), len(y_train_final))\n",
    "\n",
    "    # SAE Model\n",
    "    autoencoder, encoded, inputs = SAE_Model()\n",
    "\n",
    "    earlyStop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, min_delta=0.0075)\n",
    "    sae = autoencoder.fit(X_train_scaled, X_train_scaled,\n",
    "                epochs=EPOCH,\n",
    "                batch_size=BATCHSIZE,\n",
    "                verbose=False,\n",
    "                callbacks=[earlyStop],\n",
    "                validation_data=(X_test_scaled, X_test_scaled))\n",
    "\n",
    "    # Middle layer encoder to output\n",
    "    encoder = Model(inputs=inputs, outputs=encoded, name='encoder')\n",
    "    encoder_output = encoder.predict(X_train_final)\n",
    "\n",
    "    sae_svm_model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "    sae_svm_model.fit(encoder_output, y_train_final)\n",
    "\n",
    "    # SAE-SVM predictions\n",
    "    sae_svm_preds = sae_svm_model.predict(encoder.predict(X_test_scaled))\n",
    "    sae_output_preds.append(sae_svm_preds)\n",
    "\n",
    "    # SVM predictions\n",
    "    svm_model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "    svm_model.fit(X_train_final, y_train_final)\n",
    "    svm_preds = svm_model.predict(X_test_scaled)\n",
    "    svm_output_preds.append(svm_preds)\n",
    "\n",
    "    y_output_test.append(y_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ngS4UIWkWxB"
   },
   "source": [
    "# Five Fold Cross Validation Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HnMsDcLPkUF7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "# convert the time in dataframe to hour of the day\n",
    "df['Time'] = df['Time'].apply(lambda x: x/3600 % 24)\n",
    "\n",
    "# log on the amounts, handle zero\n",
    "# Gemini suggestion to fix issue of 0 in \"Amount\" column\n",
    "df['Amount'] = df['Amount'].apply(lambda x: np.log(x + 1e-10) if x > 0 else np.log(1e-10)) # Added a small constant (1e-10) to handle zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "of2Q3WrimIIt",
    "outputId": "97c4883a-63f2-4cc1-9d16-35c89c78dad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "227845 56962\n",
      "(227452, 31) (393, 31)\n",
      "(56863, 31) (99, 31)\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 467us/step\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step\n",
      "Fold 2\n",
      "227845 56962\n",
      "(227452, 31) (393, 31)\n",
      "(56863, 31) (99, 31)\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395us/step\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step\n",
      "Fold 3\n",
      "227846 56961\n",
      "(227452, 31) (394, 31)\n",
      "(56863, 31) (98, 31)\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 446us/step\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437us/step\n",
      "Fold 4\n",
      "227846 56961\n",
      "(227452, 31) (394, 31)\n",
      "(56863, 31) (98, 31)\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 492us/step\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step\n",
      "Fold 5\n",
      "227846 56961\n",
      "(227452, 31) (394, 31)\n",
      "(56863, 31) (98, 31)\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 498us/step\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455us/step\n"
     ]
    }
   ],
   "source": [
    "five_fold_validation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_QRpUx6mH41"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8lAa0CbXQAeI"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    # Calculate metrics for SVM\n",
    "    f2, precision, recall = calc_metrics(y_output_test[i], svm_output_preds[i])\n",
    "    f2_scores.append(f2)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    # Calculate metrics for SAE-SVM\n",
    "    f2_sae, precision_sae, recall_sae = calc_metrics(y_output_test[i], sae_output_preds[i])\n",
    "    f2_scores_sae.append(f2_sae)\n",
    "    precision_scores_sae.append(precision_sae)\n",
    "    recall_scores_sae.append(recall_sae)\n",
    "\n",
    "    # Append classification reports\n",
    "    svm_metrics.append(classification_report(y_output_test[i], svm_output_preds[i]))\n",
    "    sae_metrics.append(classification_report(y_output_test[i], sae_output_preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "LYkY6K4uzrFN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F2 Scores: [np.float64(0.5862831858407079), np.float64(0.7371794871794872), np.float64(0.6971677559912854), np.float64(0.7065217391304348), np.float64(0.7251082251082251)]\n",
      "SVM Precision Scores: [np.float64(0.9464285714285714), np.float64(0.9583333333333334), np.float64(0.9552238805970149), np.float64(0.9558823529411765), np.float64(0.9571428571428572)]\n",
      "SVM Recall Scores: [np.float64(0.5353535353535354), np.float64(0.696969696969697), np.float64(0.6530612244897959), np.float64(0.6632653061224489), np.float64(0.6836734693877551)]\n",
      "SAE-SVM F2 Scores: [np.float64(0.6318082788671024), np.float64(0.7537154989384289), np.float64(0.7905982905982906), np.float64(0.7618025751072961), np.float64(0.7855626326963907)]\n",
      "SAE-SVM Precision Scores: [np.float64(0.9206349206349206), np.float64(0.9466666666666667), np.float64(0.9736842105263158), np.float64(0.9594594594594594), np.float64(0.9367088607594937)]\n",
      "SAE-SVM Recall Scores: [np.float64(0.5858585858585859), np.float64(0.7171717171717171), np.float64(0.7551020408163265), np.float64(0.7244897959183674), np.float64(0.7551020408163265)]\n",
      "Average SVM F2 Score: 0.6904520786500281\n",
      "Average SVM Precision Score: 0.9546021990885907\n",
      "Average SVM Recall Score: 0.6464646464646464\n",
      "Average SAE-SVM F2 Score: 0.7446974552415018\n",
      "Average SAE-SVM Precision Score: 0.9474308236093713\n",
      "Average SAE-SVM Recall Score: 0.7075448361162646\n"
     ]
    }
   ],
   "source": [
    "print(f\"SVM F2 Scores: {f2_scores}\")\n",
    "print(f\"SVM Precision Scores: {precision_scores}\")\n",
    "print(f\"SVM Recall Scores: {recall_scores}\")\n",
    "\n",
    "print(f\"SAE-SVM F2 Scores: {f2_scores_sae}\")\n",
    "print(f\"SAE-SVM Precision Scores: {precision_scores_sae}\")\n",
    "print(f\"SAE-SVM Recall Scores: {recall_scores_sae}\")\n",
    "\n",
    "print(f\"Average SVM F2 Score: {np.mean(f2_scores)}\")\n",
    "print(f\"Average SVM Precision Score: {np.mean(precision_scores)}\")\n",
    "print(f\"Average SVM Recall Score: {np.mean(recall_scores)}\")\n",
    "\n",
    "print(f\"Average SAE-SVM F2 Score: {np.mean(f2_scores_sae)}\")\n",
    "print(f\"Average SAE-SVM Precision Score: {np.mean(precision_scores_sae)}\")\n",
    "print(f\"Average SAE-SVM Recall Score: {np.mean(recall_scores_sae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
